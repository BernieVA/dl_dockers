name: build_win_env
run-name: Build ${{ github.event.inputs.build_folder }}
on:
  workflow_dispatch:
    inputs:
      build_folder:
        description: "From which folder's environment.yml, the conda environment will be built"
        type: string   
        required: false
        default: 'win_cuda'
      target_folder:
        description: 'Envs path (must be on D drive)'
        type: string
        required: false
        default: 'D:/conda_envs_jianlins/'
      zip_vol_size:
        description: 'Max 7zip volumn size'
        type: string
        required: false
        default: '400m'
      retention_days:
        description: 'Days to keep the artifacts'
        type: int
        required: false
        default: 7

permissions:
  actions: write
  contents: read
        
jobs:
  create_env:
    runs-on: windows-latest
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'
    
    - name: Check Setting Folder
      run: |
        pwd
        ls ${{ github.event.inputs.build_folder }}
    
    - name: Cache Miniforge Environment
      uses: actions/cache@v4
      with:
        path: ${{ github.event.inputs.target_folder }}/${{ github.event.inputs.build_folder }}
        key: ${{ runner.os }}-conda-${{ hashFiles('${{ github.event.inputs.build_folder }}/environment.yml') }}
        restore-keys: |
          ${{ runner.os }}-conda-

    - name: Install miniforge
      uses: conda-incubator/setup-miniconda@v3
      with:
        auto-activate-base: true
        miniforge-version: latest
    
    - name: Create Conda Environment
      shell: pwsh
      run: |
        cd ${{ github.event.inputs.build_folder }}
        $envPath = "${{ github.event.inputs.target_folder }}/${{ github.event.inputs.build_folder }}"
        # Check if the environment directory exists
        if (Test-Path -Path $envPath) {
          Write-Host "Environment ${{ github.event.inputs.build_folder }} already exists under ${{ github.event.inputs.target_folder }}"
        } else {
          # Environment doesn't exist, proceed to create a new one
          Write-Host "Creating new environment ${{ github.event.inputs.build_folder }} under ${{ github.event.inputs.target_folder }}."
          conda env create -f environment.yml -p ${{ github.event.inputs.target_folder }}/${{ github.event.inputs.build_folder }}
        }

    - name: Set HADOOP_HOME environment variable
      run: |
        New-Item -ItemType Directory -Force -Path "C:\hadoop\bin"
        echo "HADOOP_HOME=C:\hadoop" | Out-File -FilePath $env:GITHUB_ENV -Append
        echo "C:\hadoop\bin" | Out-File -FilePath $env:GITHUB_PATH -Append

    - name: Download Hadoop DLLs for Windows
      run: |
        Invoke-WebRequest -Uri "https://github.com/steveloughran/winutils/raw/master/hadoop-3.0.0/bin/winutils.exe" -OutFile "C:\hadoop\bin\winutils.exe"
        # Assuming hadoop.dll is also required and available at a certain URL - replace this URL with the actual location for hadoop.dll
        Invoke-WebRequest -Uri "https://github.com/steveloughran/winutils/raw/master/hadoop-3.0.0/bin/hadoop.dll" -OutFile "C:\hadoop\bin\hadoop.dll"
        echo "Create .ivy folder"
        $ivyJarDir = Join-Path -Path $env:USERPROFILE -ChildPath ".ivy/jars"
        New-Item -ItemType Directory -Force -Path $ivyJarDir

    - name: Cache Ivy jars
      uses: actions/cache@v2
      with:
        path: |
          ${{ env.USERPROFILE }}\.ivy2\jars
        key: ${{ runner.os }}-ivy-${{ hashFiles('**/*.jar') }}
        restore-keys: |
          ${{ runner.os }}-ivy-

    - name: download sparknlp jars
      run: |
        $ivyDir = Join-Path -Path $env:USERPROFILE -ChildPath ".ivy"
        conda activate ${{ github.event.inputs.target_folder }}/${{ github.event.inputs.build_folder }}
        curl -o $ivyDir/spark-nlp-gpu-assembly-5.2.3.jar https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/jars/spark-nlp-gpu-assembly-5.2.3.jar
        python -c "import sparknlp; spark=sparknlp.start(gpu=True); spark.stop();"
        
    - name: copy cached jars
      run: |
        $sourceDir = Join-Path -Path $env:USERPROFILE -ChildPath ".ivy"
        Get-ChildItem -Path $sourceDir -Recurse -Filter *.jar | Copy-Item -Destination ${{ github.event.inputs.target_folder }}/${{ github.event.inputs.build_folder }}/lib/site-packages/pyspark/jars -Force

    - name: check folder
      run: |
        ls ${{ github.event.inputs.target_folder }}
        ls ${{ github.event.inputs.target_folder }}/${{ github.event.inputs.build_folder }}

        
    - name: Check for 7-Zip installation
      run: |
        if (!(Test-Path "C:\Program Files\7-Zip\7z.exe")) {
          choco install 7zip
        }
  
    - name: Compress and split folder
      run: |
        pwd
        7z a -t7z -v${{ github.event.inputs.zip_vol_size }} zipped/${{ github.event.inputs.build_folder }}.7z ${{ github.event.inputs.target_folder }}/${{ github.event.inputs.build_folder }}*
        ls zipped

    - name: Upload compressed parts as artifacts
      uses: actions/upload-artifact@v4
      with:
        name: ${{ github.event.inputs.build_folder }}
        path: zipped/*.7z.*
        retention-days: ${{ github.event.inputs.retention_days }}